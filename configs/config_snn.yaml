epochs: 50
sequence_length: 100
board_size: [9,9]
num_actions: 5
num_agents: 5
hidden_dim: 128
input_dim: 147
reward_scale: 0.2
punishment_scale: 0.2
goal_reward: 10.0
collision_punishment: -8.0
step_penalty: -0.5
cooperation_bonus: 3.0
reward_decay: 0.95
trace_length: 10
expected_expert_trajectory_length: 16
train:
  root_dir: 'dataset/5_8_28'
  min_time: 4
  max_time_dl: 60
  nb_agents: 5
  batch_size: 8
  num_workers: 0
valid:
  root_dir: 'dataset/5_8_28'
  min_time: 4
  max_time_dl: 60
  nb_agents: 5
  batch_size: 4
  num_workers: 0
lif_tau: 4.0
lif_v_threshold: 0.6
lif_tau_scale_embedding: 1.0
lif_tau_scale_attention1: 2.0
lif_tau_scale_feature_net: 3.0
lif_tau_scale_node_processor: 3.0
lif_tau_scale_edge_processor: 3.0
lif_tau_scale_message_net: 3.0
lif_tau_scale_output_net: 3.0
lif_tau_scale_output_layer: 3.0
lif_threshold_scale_embedding: 1.0
lif_threshold_scale_attention1: 0.2
lif_threshold_scale_feature_net: 0.2
lif_threshold_scale_node_processor: 0.2
lif_threshold_scale_edge_processor: 0.2
lif_threshold_scale_message_net: 0.2
lif_threshold_scale_output_net: 0.2
lif_threshold_scale_output_layer: 0.2
output_scale_embedding: 2.0
output_scale_attention1: 4.0
output_scale_feature_net: 6.0
output_scale_node_processor: 8.0
output_scale_edge_processor: 6.0
output_scale_message_net: 8.0
output_scale_output_net: 10.0
output_scale_output_layer: 4.0
input_scale: 20.0
